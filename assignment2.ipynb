{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2228d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from assignment2 import *\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f31dfb34",
   "metadata": {},
   "source": [
    "Remise électronique sur ZoneCours au plus tard le **14 avril à 23h55** de:\n",
    "\n",
    "* Ce Jupyter notebook (.ipynb) en guise de rapport, une fois les réponses ajoutées. \n",
    "* **Tous** les fichiers *.py* nécessaires pour l'exécution du notebook\n",
    "\n",
    "Le rapport **doit**:\n",
    "\n",
    "* être en format .ipynb (des points seront enlevés pour tout autre format).\n",
    "* inclure le numéro de matricule de tous les membres de l'équipe dans la première cellule (i.e. remplacez ces consignes)\n",
    "* répondre aux questions et discuter des résultats à l'aide de tables, graphiques, et cellules markdown\n",
    "\n",
    "Barème:\n",
    "\n",
    "* **35%** Exactitude des résultats\n",
    "* **25%** Discussions complètes et **concises** (cellules ``markdown'')\n",
    "* **20%** Concision du notebook (.ipynb avec minimum de code) et clarté des tables & graphiques\n",
    "* **20%** Clarté du code (.py)\n",
    "\n",
    "Dans les tables, présentez 4 décimales après le point.\n",
    "\n",
    "# Question 1\n",
    "\n",
    "Nous considérons des données historiques d'options sur le S&P 500. Le fichier suivant sont dans le répertoire courant:\n",
    "```\n",
    "215K 28 Mar 20:48 distrd_108105.csv\n",
    "2.7M 28 Mar 21:01 opprcd200201_108105.csv\n",
    " 63K 28 Mar 21:02 opprcd961203_108105.csv\n",
    "511K 28 Mar 20:45 secprd_108105.csv\n",
    "9.3M 28 Mar 20:43 zerocd.csv\n",
    "```\n",
    "\n",
    "Les `secprd_108105.csv` et `zerocd.csv` contiennent, respectivement, les données sur le sous-jacent et la courbe des taux sans risque (capitalisés continuement). La fonction `get_log_excess_returns` (fournie dans `assignment2.py`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac05a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_in_year = 252\n",
    "log_xreturns = get_log_excess_returns(days_in_year)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0ef3d56",
   "metadata": {},
   "source": [
    "Utilisez les paramètres initiaux suivants pour démarrer l'estimation des paramètres d'un modèle NGARCH en date du 1996-12-31. Utilisez la notation suivante:\n",
    "\n",
    "\\begin{align*}\n",
    "r_{t+1} - r_{f} &= \\lambda \\sqrt{h_{t+1}}-\\frac{1}{2}h_{t+1}+\\sqrt{h_{t+1}}%\n",
    "\\varepsilon _{t+1}, \\\\\n",
    "h_{t+1}& =\\omega +\\alpha h_{t}\\left( \\varepsilon _{t}-\\gamma \\right)\n",
    "^{2}+\\beta h_{t}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43712678",
   "metadata": {},
   "source": [
    "Quels paramètres obtenez vous en maximisant la vraisemblance des rendements au 1996-12-31? Répétez l'exercice au 2020-02-01. Tabulez les paramètres de façon à pouvoir comparer les deux jeux de paramètres aisément. Ajoutez à votre table \n",
    "\n",
    "- la volatilité inconditionnelle (annualisée)\n",
    "- la volatilité conditionnelle (annualisée) prédite au lendemain de l'estimation\n",
    "- la correlation conditionnelle en $t$ entre $r_{t+1}$ et $h_{t+2}$\n",
    "- la volatilité conditionnelle en $t$ de la variance $h_{t+2}$\n",
    "\n",
    "que les paramètres impliques. De plus, inspirez-vous de la `note_on_erp.ipynb` et définissez une fonction:\n",
    "```\n",
    "def plot_var_forecasts(horizon, P, Q, annualized=False):\n",
    "```\n",
    "que vous appelerez avec `annualized=True` sur des simulations résultant des deux différents jeux de paramètres. Discutez des paramètres, des figures et des implications aux point de vue de la validité de la spécification (vs *misspecification*) du NGARCH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs pour initialiser le MLE\n",
    "time_t = np.datetime64('1996-12-31')\n",
    "ng1996 = ngarch.initialize_at(time_t, log_xreturns, days_in_year)\n",
    "\n",
    "time_t = np.datetime64('2020-02-01')\n",
    "ng2020 = ngarch.initialize_at(time_t, log_xreturns, days_in_year)\n",
    "\n",
    "# MLE + nouveaux paramètres NGARCH\n",
    "ng1996 = f_NGARCH(ng1996)\n",
    "ng2020 = f_NGARCH(ng2020)\n",
    "\n",
    "# Table de sortie\n",
    "out_Q1 = f_out_format_Q1([ng1996, ng2020])\n",
    "out_Q1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs pour les simulations\n",
    "S_t0    = 100\n",
    "n_days  = 10*days_in_year\n",
    "n_paths = 10000 \n",
    "\n",
    "# Simulation sous P\n",
    "P_1996 = measure( *ng1996.simulateP(S_t0,n_days,n_paths,ng1996.P_predict_h()))\n",
    "P_2020 = measure( *ng2020.simulateP(S_t0,n_days,n_paths,ng2020.P_predict_h()))\n",
    "\n",
    "# Simulation sous Q\n",
    "Q_1996 = measure( *ng1996.simulateQ(S_t0,n_days,n_paths,ng1996.Q_predict_h()))\n",
    "Q_2020 = measure( *ng2020.simulateQ(S_t0,n_days,n_paths,ng2020.Q_predict_h(),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphique des variances conditionnelles prévues\n",
    "horizon    = np.arange(1,n_days+2) / days_in_year\n",
    "\n",
    "plt_1996 = plot_var_forecasts(horizon, P_1996, Q_1996, annualized=True)\n",
    "plt_1996.set_title(\"Conditionnal Variance Forecast (1996-12-31)\")\n",
    "\n",
    "plt_2020 = plot_var_forecasts(horizon, P_2020, Q_2020, annualized=True)\n",
    "plt_2020.set_title(\"Conditionnal Variance Forecast (2020-02-01)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86dd8ba8",
   "metadata": {},
   "source": [
    "NOTE : Variance plus grande sous Q que sous P car on surpondère les évènements extrême. DOnc queux de distribution plus lourde et donc, variance plus lourde."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b3ed7",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Nous souhaitons tarifer les options aux deux dates pour lesquelles nous avons estimé les paramètres ci-haut. Avant de procédez, comparer qualitativement les deux jeux de données. Soutenez votre propos à l'aide de statistiques descriptives (tables) et de figures au besoin. Quels filtres devrait-on appliquer aux données avant procéder à la tarification des options? Justifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction de la table descriptive\n",
    "options96   = pd.read_csv('opprcd961203_108105.csv', index_col=0).reset_index(drop=True)\n",
    "options20   = pd.read_csv('opprcd200201_108105.csv', index_col=0).reset_index(drop=True)\n",
    "option_info = pd.concat([options96, options20])\n",
    "\n",
    "f_describe_table(option_info).dropna(axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1445ee78",
   "metadata": {},
   "source": [
    "La première étape, avant même de construire la table de statistiques descriptives, a été d'enlever les données pour lesquelles on a une volatilité implicite manquante. C'est le premier filtre à appliquer aux données avant la tarification. Il est ensuite possible de comparer les deux jeux de données à l'aide de la table ci-dessus.\n",
    "\n",
    "Le premier constat frappant est la différence entre le nombre d'option pour lesquels on a des données. En effet, il y en a plus de 43 fois plus en 2020 qu'en 1996. L'intervalle de prix d'exercice possible a aussi beaucoup augmenté. Par exemple, pour les puts, on voit que le prix d'exercice minimal est plus bas en 2020 qu'en 1996, et ce, malgré le fait que le prix du S&P500 a beaucoup augmenté depuis. Ce phénomène est aussi observable à travers l'augmentation des valeurs maximales de volatilité implicite entre 1996 et 2020. Finalement, il y a aussi un écart entre les maturités offertes. On peut observer que des options autant à plus courte qu'à plus longue échéance sont disponibles en 2020 par rapport à 1996.\n",
    "\n",
    "Pour ce qui est des autres filtres à appliquer aux données avant la tarification, on doit premièrement s'assurer qu'il n'y a pas d'options avec une volatilité implicite extrême. En effet, une volatilité implicite extrême tend à ne pas représenter les vraies attentes des participants du marché. Nous fixerons à 125% la volatilité maximale pour laquelle on garde les données des options. Ensuite, on doit simplement s'assurer qu'il n'y a pas d'incohérence dans les données du delta (delta des calls entre 0 et 1 avec delta des puts entre -1 et 0). Le dernier filtre à appliquer sera sur le temps à maturité des options. Sachant que des options à très court terme peuvent se comporter de manière anormal, nous allons filtrer ceux avec une maturité de moins de 7 jours (une semaine). Nous allons aussi filtrer les options avec de très longue maturité car celles-ci manquent souvent de liquidité. La contrainte maximale pour la maturité sera de 550 jours (environ 1 an et demi).\n",
    "\n",
    "Il reste maintenant à appliquer les filtrations décrites. Or, on s'apperçoit à l'aide de la table descriptive qu'il sera seulement nécessaire de filtrer les données de 2020 par rapport au temps restant avant la maturité. C'est ce qui est fait ci-dessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtration des données \n",
    "option_info = option_info[option_info['DTM'] > 7].reset_index(drop = True)\n",
    "option_info = option_info[option_info['DTM'] < 550].reset_index(drop = True)\n",
    "option_info = f_clean_table(option_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f60e7",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Afin de tarifer les options, nous devons calculer, pour chaque paire $(t,T)$, le prix ex-dividendes du sous-jacent. Dans le cas du S&P 500, deux options s'offre à nous:\n",
    "\n",
    "1. Utiliser en $t$ le taux de dividende prévu ($y$, en termes annuels) par OptionMetrics pour calculer $S(t) e^{-y(T-t)}$.\n",
    "\n",
    "2. Utiliser l'approche du Cboe pour calculer le option-implied forward price $F(t,T)$ et la courbe des taux fournis par OptionMetrics (`zerocd.csv`). Ensuite, calculer le ex-dividend price $F(t,T) e^{-r_{t,T} (T-t)}$, où $r_{t,T}$ est le taux sans risque à $t$ pour une maturité à $T$, \n",
    "\n",
    "Comparer les résultats obtenus à les des deux approches. Comment et pourquoi diffèrent-ils selon vous? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc77ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les données de dividende et de prix \n",
    "S = load_price()\n",
    "\n",
    "# Méthode 1 (PAS CERTAIN SI ON DOIT PRENDRE .exdate OU .date POUR LE DIVIDENDE)\n",
    "S_t = get_price(option_info.date)\n",
    "y_T = get_dividend_rate(option_info.exdate)\n",
    "T   = option_info.DTM\n",
    "\n",
    "exdiv_1 = S_t * np.exp(-y_T * (T/days_in_year))\n",
    "\n",
    "# Méthode 2\n",
    "# Note : différent F pour chaque maturité (on doit fixer T pour trouver F à chaque fois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b728499",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Notez que sous BMS, un call\n",
    "\\begin{align*}\n",
    " c(t,T,K) &= \\hat{S}(t) N(d_1) - Ke^{-r_f(T-t)} N(d_2) \\\\\n",
    "% \\textrm{avec} \n",
    " d_i &= \\frac{\\log\\frac{\\hat{S}(t)}{K} + \\left(r_f \\pm \\frac{1}{2}\\sigma^2 \\right) (T-t)\n",
    "     }{\\sigma\\sqrt{T-t}}\n",
    "\\end{align*}\n",
    "avec $\\hat{S}(t) = S(t)e^{-y(T-t)} = F(t,T)e^{-r_f(T-t)}$. L'argument est similaire pour un put. On peut donc calculer les volatilités implicites de chaque option avec l'approche utilisée dans le TP1, avec $y=0$, mais en utilisant les prix ex-dividendes obtenus en Question 3. \n",
    "\n",
    "Comparer les 2 volatilités implicites ainsi obtenues avec celle fournie par OptionMetrics (`impl_volatility`). Illustrer votre comparaison. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd25e8",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "Dans la même optique, dénotons $\\tilde{R}_{t,T}^{(j)} = \\exp\\left\\lbrace\\sum_{k=1}^{T-t} r_{t+k}^{(j)} - r_f\\right\\rbrace$ le rendement excédentaire à terme obtenus par simulation du modèle NGARCH. Notez que le payoff actualisé d'une option peut être écrit \n",
    "\\begin{align*}\n",
    "  \\mathcal{O}^{(j)}_{i} = e^{-r_{t,T_i} (T_i-t)}\\max\\left\\lbrace 0, cp_i\\left(F_{t,T_i} \\tilde{R}_{t,T_i}^{(j)} - K\\right) \\right\\rbrace\n",
    "\\end{align*}\n",
    "où $cp_i = 1$ pour un call $i$ ($cp_i = -1$ pour le put $i$) de maturité $T_i$ et de strike $K_i$. Ainsi, seul $\\tilde{R}_{t,T}^{(j)}$ dépend de la trajectoire simulée. En $t$, en simulant une seule fois 100,000 trajectoires de longueur $T_{max} - t$, il est donc possible de tarifer toutes les options observées ce jour là.\n",
    "\n",
    "Procéder ainsi en utilisant l'un où l'autre des prix forward considérés en Question 3. Comparer les IV obtenues en Question 4, selon les prix de marché, avec les IV obtenus en appliquant la même méthode numérique au prix NGARCH. En particulier, tabuler les erreurs de tarifications, dans le domaine de la IV, en fonction d'intervalles de maturité et de moneyness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
